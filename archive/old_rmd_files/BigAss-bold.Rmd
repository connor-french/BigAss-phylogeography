---
title: "BigAss BOLD"
always_allow_html: yes
output: # use rmarkdown::render(<your-rmd-file.rmd>, output_format ="all" in the console to render both outputs
  html_notebook:
    theme: flatly
    highlight: tango
  github_document:
    toc: true
---
Load packages, read in data, and filter for NAs
```{r include = FALSE}
library(data.table)
library(tidyverse)
library(leaflet)
library(sf)
library(raster)
library(ape)
library(gdata)
library(entropy)

bold.data <- fread("../bold_data_total.txt", quote = "", na.strings = c("","NA")) %>%
  filter_at(vars(lat, lon, species_name), all_vars(!is.na(.)))


#convert to sf object for plotting
coord_points <- st_as_sf(bold.data, coords = c("lon", "lat"), 
                         crs = 4326, agr = "constant")
```

Import environmental raster layers. For the chelsa files I'm writing them to a temp file on my external hard drive before cropping since they're huge. Then, I'm making a raster of the number of individuals per cell we've obtained after filtering for at least three individuals per species per cell and plot. The outlier individuals get filtered out at the next filtering step.
```{r}

#Reading in an environmental raster (chelsa) at 30s resolution to use as a raster that utilizes lat-long coordinates for its cells. The raster isn't what's important, what is important is the raster resolution. 

#put in path where you downloaded chelsa data
#chelsa_f <- list.files("/Users/connorfrench/Dropbox/Old_Mac/climate-data/chelsa_30s_bio", full.names = TRUE) 

#path to backup hard drive
#hd_path <- "/Volumes/Connors-Backup-HD"

#t_dir <- paste0(hd_path, tempdir()) #temp directory in my external hard drive
#dir.create(t_dir, recursive = TRUE)

#using the Unarchiver commandline tools for Mac to unzip the 7zip chelsa layers. Regular unzip() does not work with 7z zipped files
#for (file in chelsa_f) {
#  system(paste("unar", file, "-o", t_dir))
#}

#list of uncompressed env'tal layers
#chelsa_uncomp <- list.files(t_dir, full.names = TRUE)

#bounds <- extent(-85, -30, -45, 15) #Reduce extent of raster to our area of interest- South America

#chelsa_clim <- stack(chelsa_uncomp) %>% #read in bioclim rasters, crop them, and downscale the resolution to 1 degree
#  crop(bounds) %>% 
#  aggregate(fact = 120) 

#remove climate layers after they've been loaded into R
#system(paste0("rm -rf ", hd_path, "/var"))

#heterogeneity layers are already clipped to South America
#hetero_f <- list.files("datasets/climate/heterogeneity", full.names = TRUE) #raster location

#raster stack of all climate layers
#sa_clim_1d <- stack(hetero_f, sa_clim_1d)

#read in stack so I don't have to re-process everything
sa_clim_1d <- stack("datasets/climate/total-clim.tif")





#get the cell number of each coordinate pair for filtering.
pts_ext_1d <- raster::extract(sa_clim_1d, coord_points, fun = "count", sp = TRUE, cellnumbers = TRUE) %>% 
  as.data.frame() %>%
  setnames(old = c("coords.x1", "coords.x2"), new = c("Long", "Lat")) %>% #rename coordinates 
  mutate(cells = as.factor(cells)) %>% #need cells numbers as factors so I can count their frequency
  group_by(species_name, cells) %>% #group the data set by species, then by cell number
  filter(n() > 2) %>% #retain only observations where there are more than two species observations per cell
  ungroup() %>%
  drop.levels()

coordinates(pts_ext_1d) <- ~Long+Lat #convert to a spatial data frame

count_pts_1d <- rasterize(pts_ext_1d, sa_clim_1d, fun = "count", field = "species_name") #make a raster out of the counts of observations per cell

pal.vert <- colorBin(palette = "inferno", bins = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100,300,500,1000,1500,2000, 3000), domain = NULL, pretty = TRUE, na.color = "#00000000")


#plot count map
leaflet(data = sa_clim_1d) %>% 
  addTiles() %>%
  addRasterImage(count_pts_1d, colors = pal.vert,  opacity = 0.8) %>%
  addLegend(pal = pal.vert, values = values(count_pts_1d))
```

Plot of the number of species per cell after filtering for cells that contain ten or more species
```{r}
pts_ext_1d_sp <- as.data.frame(pts_ext_1d) %>% #convert to data frame for filtering
  group_by(cells) %>%
  filter(n_distinct(species_name) > 9) %>%
  ungroup()


coordinates(pts_ext_1d_sp) <- ~Long+Lat #convert to a spatial data frame

count_pts_1d_sp <- rasterize(pts_ext_1d_sp, sa_clim_1d, fun = function(x, ...) {length(unique(x))}, field = "species_name") #make a raster out of the counts of species per cell

pal.species <- colorBin(palette = "inferno", bins = c(0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100,200,300,500, 1000, 2000), domain = NULL, pretty = TRUE, na.color = "#00000000")

#plot count map
leaflet(data = sa_clim_1d) %>% 
  addTiles() %>%
  addRasterImage(count_pts_1d_sp, colors = pal.species,  opacity = 0.8) %>%
  addLegend(pal = pal.species, values = values(count_pts_1d_sp))
```


Count the number of phyla per cell to characterize the higher-order taxonomic diversity per cell. This could influence calculations of genetic diversity. 
```{r}
count_pts_1_ph <- rasterize(pts_ext_1d_sp, sa_clim_1d, fun = function(x, ...) {length(unique(x))}, field = "phylum_name") #make a raster out of the counts of species per cell
pal.phylum <- colorBin(palette = "inferno", bins = c(1,2,3,4,5,6,7,8,9,10), domain = NULL, pretty = TRUE, na.color = "#00000000")


#plot phylum map
leaflet(data = sa_clim_1d) %>% 
  addTiles() %>%
  addRasterImage(count_pts_1_ph, colors = pal.phylum,  opacity = 0.8) %>%
  addLegend(pal = pal.phylum, values = values(count_pts_1_ph))
```


Write the sequence data in the BOLD csv to nexus files. Writing nexus files for species where there are at least three observations and occupy cells where there are at least nine species per cell.  Each nexus file is labeled as "speciesname.cell.nex".
```{r}
#####filter data for the ideal number of individuals and species per cell
test.nuc <- pts_ext_1d %>% 
  raster::as.data.frame(xy = TRUE) %>%
  dplyr::select(recordID, species_name, cells, markercode, nucleotides, Lat, Long, contains("total.clim")) %>% 
  distinct(recordID, .keep_all = TRUE) %>% #only retain unique individuals
  na.omit() %>%
  group_by(species_name, cells) %>% #group the data set by species, then by cell number
  filter(str_detect(markercode, "COI"), !str_detect(markercode, "COII")) %>% #Filter for only COI sequences
  filter(n() > 2) %>% #retain only cells where there are more than two species observations per cell
  ungroup() %>%
  group_by(cells) %>%
  filter(n_distinct(species_name) > 2) %>% #retain cells with 10 or more species
  ungroup() %>%
  drop.levels()



#####Code for padding short sequences with gaps
#function to pad the ends of shorter sequences with "N"s so all sequences are the same length for alignments
gap.fix.fun <- function(nuc) {
  nuc <- nuc[order(sapply(nuc, length), decreasing = TRUE)] #order sequences in descending order by length. This removes the necessity to do a bunch of unnecessary pairwise comparisons among sequences. Hashing this out because I'm ordering the data frame by sequence length before I apply this function. 
  nuc.out <- vector("list", length(nuc)) #establish an empty vector to fill
  nuc.out[[1]] <- nuc[[1]] #replace the first sequence in the out vector
  names(nuc.out) <- names(nuc) #keep the names of the input vector
  for (i in seq(2, length(nuc)))
    if(length(nuc[[i]]) <= length(nuc[[1]])) #if the sequence is shorter than the longest sequence, append the missing data designator "N" to the end of the sequence
      nuc.out[[i]] <- append(nuc[[i]], rep(c("N"), length(nuc[[1]]) - length(nuc[[i]])))
  return(nuc.out)
  }




#split data frame by cell number and species
species.seq.split.one <- test.nuc %>%
  as.data.frame() %>% #some functions don't like spatial data frames
  drop.levels() %>%
  split(.$cells) %>% #split into a list of data frames, grouped by cell. Splitting by both cells and species at once doesn't work.
  lapply(drop.levels) %>% #drop any levels in the data frame. Have to perform first because extra factor levels can mess up the split function
  lapply(function(x){
    split(x, x$species_name)}) %>% #split each cell by species
  drop.levels()

#create directory to put nexus files
dir.create("../bold-seqs-3")
#function to write nexus files
nexus.write.fun <- function(x) {
  for (i in seq_along(x)) {
    df <- x[[i]]
    for (j in seq_along(df)) {
      nuc.df <- as.data.frame(df[[j]]) #loop through each species per cell
      nuc.df <- nuc.df[order(sapply(nuc.df[,5], length), decreasing = TRUE),] #order df by nucleotide length (need to do this for padding short sequences with "N"s)
      nuc.vec <- strsplit(nuc.df[,5], "") #nucleotide column. Need to split nucleotides into individual characters.
      names(nuc.vec) <- paste(nuc.df[,1]) #names are the recordIDs
      nuc.pad <- gap.fix.fun(nuc.vec) #pad nucleotides with "N"s
      write.nexus.data(nuc.pad, file = paste0("../bold-seqs-3/", str_replace(unique(nuc.df[,2]), " ", "-"), ".", unique(nuc.df[,3]), ".nex"), missing = "N", interleaved = FALSE) #write to a nexus file, which is named by the species and cell number
    }
  }
}

nexus.write.fun(species.seq.split.one)

```

A few functions to calculate mean pi per species per cell, the number of sequences per species per cell, and the second Hill number per cell. I'm aligning sequences with clustal omega after reading them in. Note* using clustal omega in the ape R package requires having a copy of clustal omega downloaded and accessible either through their PATH or have it indicated in the clustalomega() argument.
```{r}
#create function to read, align, and calculate mean raw genetic distance (pi) from the sequences.
gen.calc.fun <- function(x) {
  #print(x) #print if debugging
  rawseq <- read.nexus.data(x)
  binseq <- as.DNAbin(rawseq)
  alignseq <- clustalomega(binseq) 
  dist <- dist.dna(alignseq, model = "raw")
  return(mean(dist))
}


## Get one hill number from a list of genetic distances. Original python code written by Isaac Overcast
hill.calc <- function(dists, order) { 
  if (order == 0) {
    return(length(dists))
  }
  if (order == 1) {
    h1 = exp(entropy::entropy(dists))
    return(h1)
  }
  else {
    tot = sum(dists)
    proportions = dists[dists > 0]/tot
    prop_order = proportions**order
    h2 = sum(prop_order)**(1/(1-order))
    return(h2)
  }
}
```


Calculate genetic diversity statistics for each cell. I had to manually edit several nexus files due to some sequences denoting gaps with spaces and some using dashes.
```{r}
#get a list of the nexus files
files <- paste0("../bold-seqs-3/", list.files("../bold-seqs-3"))

#only run if I need to re-calculate pi for everything. Takes forever
pi.total.one <- files %>% sapply(gen.calc.fun) #calculate pi for all each species within each cell

#function to only extract cell number from the name of the sequence. Some species names include a number, so I need to extract only the last number grouping
sec.num.fun <- function(n) {
  for (i in seq_along(n)) {
    if (length(n[[i]]) > 1){
      n[[i]] <- n[[i]][length(n[[i]])]
    }
  }
  return(n)
}

pi.names.one <- str_match_all(names(pi.total.one), "[0-9]+") %>% sec.num.fun() %>% unlist() #make a vector of the cell numbers for each pi calculation

pi.df.one <- bind_cols(cells = pi.names.one, pi = unname(pi.total.one)) #create dataframe of pi calculations
###I wrote this to a csv so I don't have to re-run the pi calculation script
write.csv(pi.df.one, file = "raw-pi-3.csv")
pi.df.one <- fread("raw-pi-10.csv")


#function to calculate pi for each cell number. I'm using dplyr::summarise because plyr also has a summarise function that can create a lot of confusion. nspec is the number of species per cell that were filtered
pi.summary.fun <- function(df, nspec) {
  gdf <- group_by(df, cells)
  sdf <- sample_n(gdf, nspec)
  sum.df <- dplyr::summarise(sdf, median.pi = median(pi), mean.pi = mean(pi), sd.pi = sd(pi), hill.zero = hill.calc(pi, 0), hill.one = hill.calc(pi, 1), hill.two = hill.calc(pi, 2), shannon = entropy::entropy(pi))
  return(sum.df)
}


#replicate the sampling 1000 times. 
sum.list<- replicate(1000, pi.summary.fun(pi.df.one, 10), simplify = FALSE) 

#summarise these samples into a final df
sum.df <- bind_rows(sum.list) %>%
  group_by(cells) %>% 
  dplyr::summarise(median.pi.avg = mean(median.pi), median.pi.sd = sd(median.pi), mean.pi.avg = mean(mean.pi),  mean.pi.sd = sd(mean.pi), hill.zero.avg = mean(hill.zero), hill.zero.sd = sd(hill.zero), hill.one.avg = mean(hill.one), hill.one.sd = sd(hill.one), hill.two.avg = mean(hill.two), hill.two.sd = sd(hill.two), shannon.avg = mean(shannon), shannon.sd = sd(shannon))
write.csv(sum.df, file = "pi-summary-10.csv")
sum.df <- fread("pi-summary-10.csv")

#make new data frame including the pi values.
pi.plot <- merge(test.nuc, sum.df, by = "cells") %>% 
  raster::as.data.frame(xy = TRUE) %>% #have to convert to data frame to omit NAs
  dplyr::select(recordID, species_name, cells, markercode, median.pi.avg, median.pi.sd, mean.pi.avg, mean.pi.sd, hill.zero.avg, hill.zero.sd, hill.one.avg, hill.one.sd, hill.two.avg, hill.two.sd, shannon.avg, shannon.sd, Long, Lat, contains("total.clim")) %>%
  filter(mean.pi.avg < 0.035) %>% #cells largest pi values contain "species" which actually contain different species
  #na.omit() %>%
  drop.levels()

#convert back to a spatial data frame
coordinates(pi.plot) <- ~Long+Lat


#create new raster of mean pi values per cell
pi.raster.one <- rasterize(pi.plot, sa_clim_1d, fun = "first", field = "mean.pi.avg") 

#color palette for leaflet plot
pal.one <- colorNumeric(palette = "viridis", domain = NULL, na.color = "#00000000")

#leaflet plot
leaflet() %>% 
  addTiles() %>%
  addRasterImage(pi.raster.one, colors = pal.one,  opacity = 0.8) %>%
  addLegend(pal = pal.one, values = values(pi.raster.one))


```


MARS modeling of genetic diversity ~ environment. First model is a MARS model using generalized cross-validation
Load packages
```{r include = FALSE}
library(tidymodels)
library(earth)
library(caret)
library(ggrepel)
```


REDO THE ANALYSES WITH A RECIPE
```{r}
mars.data <- pi.plot %>% 
  raster::as.data.frame(xy = TRUE) %>% 
  filter(!duplicated(cells)) %>% 
  dplyr::select(mean.pi.avg, contains("total.clim")) %>% 
  na.omit()


#split into training and testing data
mars.split <- initial_split(mars.data, prop = 4/5)

###########create training data set##############
mars.training <- training(mars.split)

#select bioclims as features
mars.training.features <- mars.training %>% dplyr::select(contains("total.clim")) 

#select mean pi as response
mars.training.response <- mars.training %>% dplyr::select(mean.pi.avg) %>% as.matrix() %>% as.numeric()

#list of feature dataframe and response matrix
mars.training <- list(features = mars.training.features, response =  mars.training.response) 

############create testing data set############
mars.test <- testing(mars.split) 

#select bioclims as features
mars.test.features <- mars.test %>% dplyr::select(contains("total.clim")) 

#select mean pi as response
mars.test.response <- mars.test %>% dplyr::select(mean.pi.avg) %>% as.matrix() %>% as.numeric()

#list of feature dataframe and response matrix
mars.test <- list(features = mars.test.features, response =  mars.test.response) 



fplot <- featurePlot(mars.training$features, mars.training$response)
fplot

#gcv model
mars.fit.gcv <- earth(mars.training$features, mars.training$response)
mars.pred.gcv <- predict(mars.fit.gcv, mars.test$features)

mars.plot.data <- tibble(pred = as.numeric(mars.pred.gcv), obs = as.numeric(mars.test$response))

ggplot(mars.plot.data, aes(x = obs, y = pred)) +
  geom_point() +
  geom_abline(alpha = 0.5)

mars.fit.gcv

```


```{r}
#5-fold cross validation
mars.grid <- expand.grid(degree = 1:3, nprune = seq(1, 19, by = 1))

#LOOCV
ctrl <- trainControl(
  method = "LOOCV", 
  number = 10,
  # Save the assessment predictions from the best model
  savePredictions = "final",
  # Log the progress of the tuning process
  verboseIter = FALSE
  )

# Using the same seed to obtain the same 
# resamples.
set.seed(25489)
mars_mod <- train(
  mars.training$features, 
  mars.training$response,
  method = "earth",
  tuneGrid = mars.grid,
  trControl = ctrl
)

ggplot(mars_mod) + theme(legend.position = "top")
```


```{r}
mars_imp <- varImp(mars_mod)
ggplot(mars_imp, top = 20) + xlab("")

ggplot(mars_mod$pred, aes(x = pred, y = obs)) +
  geom_point() +
  geom_abline()
```


prediction performance
```{r}
mars.pred.loocv <- predict(mars_mod, mars.test.features)

mars.fit.loocv <- tibble(obs = mars.test$response, pred = as.numeric(mars.pred.loocv))

rsq(mars.fit.loocv, obs, pred)



plot(x = mars.pred.loocv, y = mars.test$response)
  
```


