mars_model
ggplot(mars_mod) + theme(legend.position = "top")
ggplot(mars_model) + theme(legend.position = "top")
# obs vs predicted plot
obs_pred_plot(mars_model, full_df_hill)
install.packages("tidymodels")
library(tidymodels)
obs_pred_plot
?obs_pred_plot
# obs vs prediction plot. Taken from Max Kuhn's Applied Predictive Modeling course in Austin at rstudioconf::2019
obs_pred_plot <- function(x, dat, cutoff = 25, ...) {
pred_dat <- x %>%
add_columns(dat, model, year) %>%
mutate(residuals = obs - pred)
ggplot(pred_dat, aes(x = pred, y = obs)) +
geom_abline(col = "green", alpha = .5) +
geom_point(alpha = .3) +
geom_smooth(
se = FALSE, col = "red",
lty = 2, lwd = .25, alpha = .5
) +
geom_text_repel(
data = dplyr::filter(pred_dat, abs(residuals) > cutoff),
aes(label = plot_label),
segment.color = "grey50"
)
}
# obs vs predicted plot
obs_pred_plot(mars_model, full_df_hill)
# obs vs prediction plot. Taken from Max Kuhn's Applied Predictive Modeling course in Austin at rstudioconf::2019
add_columns <- function(x, dat, ...) {
# capture any selectors and filter the data
dots <- quos(...)
if (!is_empty(dots))
dat <- dplyr::select(dat, year, model, !!!dots)
dat <-
x %>%
pluck("pred") %>%
arrange(rowIndex) %>%
dplyr::select(-rowIndex) %>%
bind_cols(dat)
# create a label column when possible
if (all(c("model", "year") %in% names(dat)))
dat <-
dat %>%
mutate(plot_label = paste(year, model))
dat
}
# obs vs predicted plot
obs_pred_plot(mars_model, full_df_hill)
summary(mars_model)
# obs vs prediction plot. Taken from Max Kuhn's Applied Predictive Modeling course in Austin at rstudioconf::2019
add_columns <- function(x, dat, ...) {
# capture any selectors and filter the data
dots <- quos(...)
if (!is_empty(dots))
dat <- dplyr::select(dat, model, !!!dots)
dat <-
x %>%
pluck("pred") %>%
arrange(rowIndex) %>%
dplyr::select(-rowIndex) %>%
bind_cols(dat)
# create a label column when possible
if (all(c("model") %in% names(dat)))
dat <-
dat %>%
mutate(plot_label = paste(model))
dat
}
obs_pred_plot <- function(x, dat, cutoff = 25, ...) {
pred_dat <- x %>%
add_columns(dat, model) %>%
mutate(residuals = obs - pred)
ggplot(pred_dat, aes(x = pred, y = obs)) +
geom_abline(col = "green", alpha = .5) +
geom_point(alpha = .3) +
geom_smooth(
se = FALSE, col = "red",
lty = 2, lwd = .25, alpha = .5
) +
geom_text_repel(
data = dplyr::filter(pred_dat, abs(residuals) > cutoff),
aes(label = plot_label),
segment.color = "grey50"
)
}
# obs vs predicted plot
obs_pred_plot(mars_model, full_df_hill)
mars_model$pred
head(mars_model$pred)
# obs vs predicted plot
mars_model_pred <- mars_model$pred
?geom_abline
ggplot(mars_model_pred, aes(x = obs, y = pred)) +
geom_point()
ggplot(mars_model_pred, aes(x = pred, y = obs)) +
geom_abline(col = "green", alpha = .5) +
geom_point(alpha = .3) +
geom_smooth(
se = FALSE, col = "red",
lty = 2, lwd = .25, alpha = .5
)
# obs vs predicted plot
mars_model_pred <- mars_model$pred %>%
mutate(residuals = obs - pred)
ggplot(mars_model_pred, aes(x = pred, y = obs)) +
geom_abline(col = "green", alpha = .5) +
geom_point(alpha = .3) +
geom_smooth(
se = FALSE, col = "red",
lty = 2, lwd = .25, alpha = .5
) +
geom_text_repel(
data = dplyr::filter(pred_dat, abs(residuals) > cutoff),
aes(label = plot_label),
segment.color = "grey50"
)
ggplot(mars_model_pred, aes(x = pred, y = obs)) +
geom_abline(col = "green", alpha = .5) +
geom_point(alpha = .3) +
geom_smooth(
se = FALSE, col = "red",
lty = 2, lwd = .25, alpha = .5
) +
ggrepel::geom_text_repel(
data = dplyr::filter(pred_dat, abs(residuals) > cutoff),
aes(label = plot_label),
segment.color = "grey50"
)
install.packages("ggrepel")
ggplot(mars_model_pred, aes(x = pred, y = obs)) +
geom_abline(col = "green", alpha = .5) +
geom_point(alpha = .3) +
geom_smooth(
se = FALSE, col = "red",
lty = 2, lwd = .25, alpha = .5
) +
ggrepel::geom_text_repel(
data = dplyr::filter(pred_dat, abs(residuals) > cutoff),
aes(label = plot_label),
segment.color = "grey50"
)
ggplot(mars_model_pred, aes(x = pred, y = obs)) +
geom_abline(col = "green", alpha = .5) +
geom_point(alpha = .3) +
geom_smooth(
se = FALSE, col = "red",
lty = 2, lwd = .25, alpha = .5
)
ggplot(mars_model_pred, aes(x = pred, y = obs)) +
geom_abline(col = "green", alpha = .5) +
geom_point(alpha = .3) +
geom_smooth(
se = FALSE,
col = "red",
lty = 2,
lwd = .25,
alpha = .5
) +
xlim(0, 10)
select(full_df_hill, -hill.one.avg)
ggplot(full_df_hill, aes(x = hill.one.avg)) +
geom_histogram()
seq(2, 50, by = 2)
set.seed(32378455)
mars_model <- caret::train(
x = select(full_df_hill, -hill.one.avg),
y = full_df_hill$hill.one.avg,
method = "earth",
tuneGrid = mars_grid,
trControl = ctrl
)
# average RMSE plot
ggplot(mars_model) + theme(legend.position = "top")
# obs vs predicted plot
mars_model_pred <- mars_model$pred
ggplot(mars_model_pred, aes(x = pred, y = obs)) +
geom_abline(col = "green", alpha = .5) +
geom_point(alpha = .3) +
geom_smooth(
se = FALSE,
col = "red",
lty = 2,
lwd = .25,
alpha = .5
) +
xlim(0, 10)
ggplot(mars_model_pred, aes(x = pred, y = obs)) +
geom_abline(col = "green", alpha = .5) +
geom_hex(alpha = .3) +
geom_smooth(
se = FALSE,
col = "red",
lty = 2,
lwd = .25,
alpha = .5
) +
xlim(0, 10)
install.packages("hexbin")
ggplot(mars_model_pred, aes(x = pred, y = obs)) +
geom_abline(col = "green", alpha = .5) +
geom_hex(alpha = .3) +
geom_smooth(
se = FALSE,
col = "red",
lty = 2,
lwd = .25,
alpha = .5
) +
xlim(0, 10)
ggplot(mars_model_pred, aes(x = pred, y = obs)) +
geom_abline(col = "green", alpha = .5) +
geom_hex(alpha = .3) +
scale_fill_viridis_c() +
geom_smooth(
se = FALSE,
col = "red",
lty = 2,
lwd = .25,
alpha = .5
) +
xlim(0, 10)
ggplot(mars_model_pred, aes(x = pred, y = obs)) +
geom_abline(col = "green") +
geom_hex(alpha = .3) +
scale_fill_viridis_c() +
geom_smooth(
se = FALSE,
col = "red",
lty = 2,
lwd = .25,
alpha = .5
) +
xlim(0, 10)
ggplot(mars_model_pred, aes(x = pred, y = obs)) +
geom_abline(col = "green", alpha = .5) +
geom_hex(alpha = .8) +
scale_fill_viridis_c() +
geom_smooth(
se = FALSE,
col = "red",
lty = 2,
lwd = .25,
alpha = .5
) +
xlim(0, 10)
summary(mars_model)
# average RMSE plot
ggplot(mars_model) + theme(legend.position = "top")
set.seed(323765)
mars_model <- caret::train(
x = select(full_df_hill, -hill.one.avg),
y = full_df_hill$hill.one.avg,
method = "earth",
tuneGrid = mars_grid,
trControl = ctrl
)
# average RMSE plot
ggplot(mars_model) + theme(legend.position = "top")
# obs vs predicted plot
mars_model_pred <- mars_model$pred
ggplot(mars_model_pred, aes(x = pred, y = obs)) +
geom_abline(col = "green", alpha = .5) +
geom_hex(alpha = .8) +
scale_fill_viridis_c() +
geom_smooth(
se = FALSE,
col = "red",
lty = 2,
lwd = .25,
alpha = .5
) +
xlim(0, 10)
summary(mars_model)
# set up tuning grid. We're exploring additive and interaction terms ("degree"),
rf_grid <- expand.grid(mtry = sqrt(ncol(full_df_hill)))
# set up tuning grid. We're exploring additive and interaction terms ("degree"),
rf_grid <- expand.grid(.mtry = 1:sqrt(ncol(full_df_hill)))
rf_grid
# we're performing 10-fold cross validation for all models
ctrl <- trainControl(
method = "cv",
number = 5,
# Save the assessment predictions from the best model
savePredictions = "final",
# Log the progress of the tuning process
verboseIter = TRUE,
# want to use parallelization
allowParallel = TRUE
)
# first hill number analysis
full_df_hill <- full_df %>%
select(
hill.one.avg,
latitude,
longitude,
starts_with("chelsa"),
starts_with("dhi"),
starts_with("hetero"),
starts_with("pc"),
starts_with("soil")
) %>%
na.omit()
# set up tuning grid. We're exploring additive and interaction terms ("degree"),
mars_grid <- expand.grid(degree = 1:2, nprune = seq(2, 50, by = 2))
set.seed(334565)
mars_model <- caret::train(
x = select(full_df_hill, -hill.one.avg),
y = full_df_hill$hill.one.avg,
method = "earth",
tuneGrid = mars_grid,
trControl = ctrl
)
# average RMSE plot
ggplot(mars_model) + theme(legend.position = "top")
# obs vs predicted plot
mars_model_pred <- mars_model$pred
ggplot(mars_model_pred, aes(x = pred, y = obs)) +
geom_abline(col = "green", alpha = .5) +
geom_hex(alpha = .8) +
scale_fill_viridis_c() +
geom_smooth(
se = FALSE,
col = "red",
lty = 2,
lwd = .25,
alpha = .5
) +
xlim(0, 10)
var_importance <- tibble(
variable = dimnames(evimp(mars_model))[[1]],
num_subsets = c(22, 21, 18, 15, 14, 12, 10, 9, 6, 5)
)
summary(mars_model)
# we're performing 10-fold cross validation for all models
ctrl <- trainControl(
method = "repeatedcv",
number = 10,
repeats = 3,
# Save the assessment predictions from the best model
savePredictions = "final",
# Log the progress of the tuning process
verboseIter = TRUE,
# want to use parallelization
allowParallel = TRUE
)
set.seed(8379404957)
set.seed(837957)
rf_model <- caret::train(
x = select(full_df_hill, -hill.one.avg),
y = full_df_hill$hill.one.avg,
method = "rf",
tuneGrid = rf_grid,
trControl = ctrl,
ntree = 1000
)
set.seed(83054)
rf_model <- caret::train(
x = select(full_df_hill, -hill.one.avg),
y = full_df_hill$hill.one.avg,
method = "rf",
tuneGrid = rf_grid,
trControl = ctrl,
ntree = 1000
)
warnings()
summary(rf_model)
getwd()
saveRDS(rf_model, file = "rf_model_10-28-19.rds")
plot(rf_model)
rf_model$
######################################################
################### Extra Plots ######################
######################################################
dhi_plot <- ggplot(sum_df_processed, aes(x = dhi_1, y = hill.one.avg)) +
geom_point(color = "gold") +
geom_smooth(method = "lm", se = FALSE, color = "purple") +
labs(x = "DHI 3: Seasonality", y = "Avg Hill One") +
theme(text = element_text(size=35, color = "white"),
panel.background = element_rect(fill = "transparent"), # bg of the panel
plot.background = element_rect(fill = "transparent", color = NA), # bg of the plot
panel.grid.major = element_blank(), # get rid of major grid
legend.text=element_text(color = "white"),
legend.title = element_text(color = "white"),
panel.grid.minor = element_blank(), # get rid of minor grid
legend.background = element_rect(fill = "transparent", color = "white"), # get rid of legend bg
legend.box.background = element_rect(fill = "transparent"), # get rid of legend panel bg)
axis.text.x = element_text(color = "white"),
axis.text.y = element_text(color = "white")
)
rf_model$finalModel
summary(rf_model$finalModel)
rf_model$results
# we're performing 10-fold cross validation for all models
ctrl <- trainControl(
method = "cv",
number = 10,
# Save the assessment predictions from the best model
savePredictions = "final",
# Log the progress of the tuning process
verboseIter = TRUE,
# want to use parallelization
allowParallel = TRUE
)
# first hill number analysis
full_df_pi <- full_df %>%
select(
mean.pi.avg,
latitude,
longitude,
starts_with("chelsa"),
starts_with("dhi"),
starts_with("hetero"),
starts_with("pc"),
starts_with("soil")
) %>%
na.omit()
#### MARS model
# set up tuning grid. We're exploring additive and interaction terms ("degree"),
mars_grid <- expand.grid(degree = 1:2, nprune = seq(2, 50, by = 2))
set.seed(3453465)
mars_model <- caret::train(
x = select(full_df_pi, -mean.pi.avg),
y = full_df_pi$mean.pi.avg,
method = "earth",
tuneGrid = mars_grid,
trControl = ctrl
)
# average RMSE plot
ggplot(mars_model) + theme(legend.position = "top")
# obs vs predicted plot
mars_model_pred <- mars_model$pred
ggplot(mars_model_pred, aes(x = pred, y = obs)) +
geom_abline(col = "green", alpha = .5) +
geom_hex(alpha = .8) +
scale_fill_viridis_c() +
geom_smooth(
se = FALSE,
col = "red",
lty = 2,
lwd = .25,
alpha = .5
) +
xlim(0, 10)
ggplot(mars_model_pred, aes(x = pred, y = obs)) +
geom_abline(col = "green", alpha = .5) +
geom_point(alpha = .8) +
geom_smooth(
se = FALSE,
col = "red",
lty = 2,
lwd = .25,
alpha = .5
) +
xlim(0, 10)
mars_model_pred$pred
hist(mars_model_pred$pred)
ggplot(mars_model_pred, aes(x = pred)) +
geom_histogram(bins = 50)
summary(mars_model)
# set up tuning grid. We're exploring additive and interaction terms ("degree"),
set.seed(833472)
rf_model_pi <- caret::train(
x = select(full_df_pi, -mean.pi.avg),
y = full_df_pi$mean.pi.avg,
method = "rf",
tuneGrid = rf_grid,
trControl = ctrl,
ntree = 1000
)
rf_model$results
rf_model_pi$results
install.packages("devtools")
# install.packages("devtools")
devtools::install_github("thomasp85/patchwork")
library(reticulate)
use_condaenv("pop-gene")
knitr::opts_chunk$set(echo = TRUE)
py_config()
py_discover_config()
?Startup
Sys.getenv()
Sys.setenv(RETICULATE_PYTHON = "")
Sys.getenv()
library(reticulate)
use_condaenv("pop-gene")
repl_python()
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
use_condaenv("pop-gene")
knitr::opts_chunk$set(echo = TRUE)
py_config()
Sys.getenv()
?use_condaenv
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
use_condaenv("pop-gene")
reticulate::source_python()
conda_list()
use_condaenv("pop-gene", required = TRUE)
use_condaenv("pop-gen", required = TRUE)
file.path(getwd(), ".Rprofile")
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
use_condaenv("pop-gen", required = TRUE)
reticulate::py_config()
library(reticulate)
use_condaenv("pop-gen", required = TRUE)
library(reticulate)
use_condaenv("pop-gen", required = TRUE)
knitr::opts_chunk$set(echo = TRUE)
